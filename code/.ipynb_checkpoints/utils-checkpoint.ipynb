{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import world\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch import log\n",
    "from dataloader import BasicDataset\n",
    "from time import time\n",
    "from model import LightGCN\n",
    "from model import PairWiseModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "import os\n",
    "try:\n",
    "    from cppimport import imp_from_filepath\n",
    "    from os.path import join, dirname\n",
    "    path = join(dirname(__file__), \"sources/sampling.cpp\")\n",
    "    sampling = imp_from_filepath(path)\n",
    "    sampling.seed(world.seed)\n",
    "    sample_ext = True\n",
    "except:\n",
    "    world.cprint(\"Cpp extension not loaded\")\n",
    "    sample_ext = False\n",
    "\n",
    "\n",
    "class BPRLoss:\n",
    "    def __init__(self,\n",
    "                 recmodel : PairWiseModel,\n",
    "                 config : dict):\n",
    "        self.model = recmodel\n",
    "        self.weight_decay = config['decay']\n",
    "        self.lr = config['lr']\n",
    "        self.opt = optim.Adam(recmodel.parameters(), lr=self.lr)\n",
    "\n",
    "    def stageOne(self, users, pos, neg):\n",
    "        loss, reg_loss = self.model.bpr_loss(users, pos, neg)\n",
    "        reg_loss = reg_loss*self.weight_decay\n",
    "        loss = loss + reg_loss\n",
    "\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "        return loss.cpu().item()\n",
    "\n",
    "\n",
    "def UniformSample_original(dataset, neg_ratio = 1):\n",
    "    dataset : BasicDataset\n",
    "    allPos = dataset.allPos\n",
    "    start = time()\n",
    "    if sample_ext:\n",
    "        S = sampling.sample_negative(dataset.n_users, dataset.m_items,\n",
    "                                     dataset.trainDataSize, allPos, neg_ratio)\n",
    "    else:\n",
    "        S = UniformSample_original_python(dataset)\n",
    "    return S\n",
    "\n",
    "def UniformSample_original_python(dataset):\n",
    "    \"\"\"\n",
    "    the original impliment of BPR Sampling in LightGCN\n",
    "    :return:\n",
    "        np.array\n",
    "    \"\"\"\n",
    "    total_start = time()\n",
    "    dataset : BasicDataset\n",
    "    user_num = dataset.trainDataSize\n",
    "    users = np.random.randint(0, dataset.n_users, user_num)\n",
    "    allPos = dataset.allPos\n",
    "    S = []\n",
    "    sample_time1 = 0.\n",
    "    sample_time2 = 0.\n",
    "    for i, user in enumerate(users):\n",
    "        start = time()\n",
    "        posForUser = allPos[user]\n",
    "        if len(posForUser) == 0:\n",
    "            continue\n",
    "        sample_time2 += time() - start\n",
    "        posindex = np.random.randint(0, len(posForUser))\n",
    "        positem = posForUser[posindex]\n",
    "        while True:\n",
    "            negitem = np.random.randint(0, dataset.m_items)\n",
    "            if negitem in posForUser:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        S.append([user, positem, negitem])\n",
    "        end = time()\n",
    "        sample_time1 += end - start\n",
    "    total = time() - total_start\n",
    "    return np.array(S)\n",
    "\n",
    "# ===================end samplers==========================\n",
    "# =====================utils====================================\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def getFileName():\n",
    "    if world.model_name == 'mf':\n",
    "        file = f\"mf-{world.dataset}-{world.config['latent_dim_rec']}.pth.tar\"\n",
    "    elif world.model_name == 'lgn':\n",
    "        file = f\"lgn-{world.dataset}-{world.config['lightGCN_n_layers']}-{world.config['latent_dim_rec']}.pth.tar\"\n",
    "    return os.path.join(world.FILE_PATH,file)\n",
    "\n",
    "def minibatch(*tensors, **kwargs):\n",
    "\n",
    "    batch_size = kwargs.get('batch_size', world.config['bpr_batch_size'])\n",
    "\n",
    "    if len(tensors) == 1:\n",
    "        tensor = tensors[0]\n",
    "        for i in range(0, len(tensor), batch_size):\n",
    "            yield tensor[i:i + batch_size]\n",
    "    else:\n",
    "        for i in range(0, len(tensors[0]), batch_size):\n",
    "            yield tuple(x[i:i + batch_size] for x in tensors)\n",
    "\n",
    "\n",
    "def shuffle(*arrays, **kwargs):\n",
    "\n",
    "    require_indices = kwargs.get('indices', False)\n",
    "\n",
    "    if len(set(len(x) for x in arrays)) != 1:\n",
    "        raise ValueError('All inputs to shuffle must have '\n",
    "                         'the same length.')\n",
    "\n",
    "    shuffle_indices = np.arange(len(arrays[0]))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    if len(arrays) == 1:\n",
    "        result = arrays[0][shuffle_indices]\n",
    "    else:\n",
    "        result = tuple(x[shuffle_indices] for x in arrays)\n",
    "\n",
    "    if require_indices:\n",
    "        return result, shuffle_indices\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "class timer:\n",
    "    \"\"\"\n",
    "    Time context manager for code block\n",
    "        with timer():\n",
    "            do something\n",
    "        timer.get()\n",
    "    \"\"\"\n",
    "    from time import time\n",
    "    TAPE = [-1]  # global time record\n",
    "    NAMED_TAPE = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        if len(timer.TAPE) > 1:\n",
    "            return timer.TAPE.pop()\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    @staticmethod\n",
    "    def dict(select_keys=None):\n",
    "        hint = \"|\"\n",
    "        if select_keys is None:\n",
    "            for key, value in timer.NAMED_TAPE.items():\n",
    "                hint = hint + f\"{key}:{value:.2f}|\"\n",
    "        else:\n",
    "            for key in select_keys:\n",
    "                value = timer.NAMED_TAPE[key]\n",
    "                hint = hint + f\"{key}:{value:.2f}|\"\n",
    "        return hint\n",
    "\n",
    "    @staticmethod\n",
    "    def zero(select_keys=None):\n",
    "        if select_keys is None:\n",
    "            for key, value in timer.NAMED_TAPE.items():\n",
    "                timer.NAMED_TAPE[key] = 0\n",
    "        else:\n",
    "            for key in select_keys:\n",
    "                timer.NAMED_TAPE[key] = 0\n",
    "\n",
    "    def __init__(self, tape=None, **kwargs):\n",
    "        if kwargs.get('name'):\n",
    "            timer.NAMED_TAPE[kwargs['name']] = timer.NAMED_TAPE[\n",
    "                kwargs['name']] if timer.NAMED_TAPE.get(kwargs['name']) else 0.\n",
    "            self.named = kwargs['name']\n",
    "            if kwargs.get(\"group\"):\n",
    "                #TODO: add group function\n",
    "                pass\n",
    "        else:\n",
    "            self.named = False\n",
    "            self.tape = tape or timer.TAPE\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timer.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.named:\n",
    "            timer.NAMED_TAPE[self.named] += timer.time() - self.start\n",
    "        else:\n",
    "            self.tape.append(timer.time() - self.start)\n",
    "\n",
    "\n",
    "# ====================Metrics==============================\n",
    "# =========================================================\n",
    "def RecallPrecision_ATk(test_data, r, k):\n",
    "    \"\"\"\n",
    "    test_data should be a list? cause users may have different amount of pos items. shape (test_batch, k)\n",
    "    pred_data : shape (test_batch, k) NOTE: pred_data should be pre-sorted\n",
    "    k : top-k\n",
    "    \"\"\"\n",
    "    right_pred = r[:, :k].sum(1)\n",
    "    precis_n = k\n",
    "    recall_n = np.array([len(test_data[i]) for i in range(len(test_data))])\n",
    "    recall = np.sum(right_pred/recall_n)\n",
    "    precis = np.sum(right_pred)/precis_n\n",
    "    return {'recall': recall, 'precision': precis}\n",
    "\n",
    "\n",
    "def MRRatK_r(r, k):\n",
    "    \"\"\"\n",
    "    Mean Reciprocal Rank\n",
    "    \"\"\"\n",
    "    pred_data = r[:, :k]\n",
    "    scores = np.log2(1./np.arange(1, k+1))\n",
    "    pred_data = pred_data/scores\n",
    "    pred_data = pred_data.sum(1)\n",
    "    return np.sum(pred_data)\n",
    "\n",
    "def NDCGatK_r(test_data,r,k):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain\n",
    "    rel_i = 1 or 0, so 2^{rel_i} - 1 = 1 or 0\n",
    "    \"\"\"\n",
    "    assert len(r) == len(test_data)\n",
    "    pred_data = r[:, :k]\n",
    "\n",
    "    test_matrix = np.zeros((len(pred_data), k))\n",
    "    for i, items in enumerate(test_data):\n",
    "        length = k if k <= len(items) else len(items)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = np.sum(max_r * 1./np.log2(np.arange(2, k + 2)), axis=1)\n",
    "    dcg = pred_data*(1./np.log2(np.arange(2, k + 2)))\n",
    "    dcg = np.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg/idcg\n",
    "    ndcg[np.isnan(ndcg)] = 0.\n",
    "    return np.sum(ndcg)\n",
    "\n",
    "def AUC(all_item_scores, dataset, test_data):\n",
    "    \"\"\"\n",
    "        design for a single user\n",
    "    \"\"\"\n",
    "    dataset : BasicDataset\n",
    "    r_all = np.zeros((dataset.m_items, ))\n",
    "    r_all[test_data] = 1\n",
    "    r = r_all[all_item_scores >= 0]\n",
    "    test_item_scores = all_item_scores[all_item_scores >= 0]\n",
    "    return roc_auc_score(r, test_item_scores)\n",
    "\n",
    "def getLabel(test_data, pred_data):\n",
    "    r = []\n",
    "    for i in range(len(test_data)):\n",
    "        groundTrue = test_data[i]\n",
    "        predictTopK = pred_data[i]\n",
    "        pred = list(map(lambda x: x in groundTrue, predictTopK))\n",
    "        pred = np.array(pred).astype(\"float\")\n",
    "        r.append(pred)\n",
    "    return np.array(r).astype('float')\n",
    "\n",
    "# ====================end Metrics=============================\n",
    "# ========================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
