{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import world\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import dataloader\n",
    "from pprint import pprint\n",
    "from utils import timer\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import model\n",
    "import multiprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "CORES = multiprocessing.cpu_count() // 2\n",
    "\n",
    "\n",
    "def BPR_train_original(dataset, recommend_model, loss_class, epoch, neg_k=1, w=None):\n",
    "    Recmodel = recommend_model\n",
    "    Recmodel.train()\n",
    "    bpr: utils.BPRLoss = loss_class\n",
    "    \n",
    "    with timer(name=\"Sample\"):\n",
    "        S = utils.UniformSample_original(dataset)\n",
    "    users = torch.Tensor(S[:, 0]).long()\n",
    "    posItems = torch.Tensor(S[:, 1]).long()\n",
    "    negItems = torch.Tensor(S[:, 2]).long()\n",
    "\n",
    "    users = users.to(world.device)\n",
    "    posItems = posItems.to(world.device)\n",
    "    negItems = negItems.to(world.device)\n",
    "    users, posItems, negItems = utils.shuffle(users, posItems, negItems)\n",
    "    total_batch = len(users) // world.config['bpr_batch_size'] + 1\n",
    "    aver_loss = 0.\n",
    "    for (batch_i,\n",
    "         (batch_users,\n",
    "          batch_pos,\n",
    "          batch_neg)) in enumerate(utils.minibatch(users,\n",
    "                                                   posItems,\n",
    "                                                   negItems,\n",
    "                                                   batch_size=world.config['bpr_batch_size'])):\n",
    "        cri = bpr.stageOne(batch_users, batch_pos, batch_neg)\n",
    "        aver_loss += cri\n",
    "        if world.tensorboard:\n",
    "            w.add_scalar(f'BPRLoss/BPR', cri, epoch * int(len(users) / world.config['bpr_batch_size']) + batch_i)\n",
    "    aver_loss = aver_loss / total_batch\n",
    "    time_info = timer.dict()\n",
    "    timer.zero()\n",
    "    return f\"loss{aver_loss:.3f}-{time_info}\"\n",
    "    \n",
    "    \n",
    "def test_one_batch(X):\n",
    "    sorted_items = X[0].numpy()\n",
    "    groundTrue = X[1]\n",
    "    r = utils.getLabel(groundTrue, sorted_items)\n",
    "    pre, recall, ndcg = [], [], []\n",
    "    for k in world.topks:\n",
    "        ret = utils.RecallPrecision_ATk(groundTrue, r, k)\n",
    "        pre.append(ret['precision'])\n",
    "        recall.append(ret['recall'])\n",
    "        ndcg.append(utils.NDCGatK_r(groundTrue,r,k))\n",
    "    return {'recall':np.array(recall), \n",
    "            'precision':np.array(pre), \n",
    "            'ndcg':np.array(ndcg)}\n",
    "        \n",
    "            \n",
    "def Test(dataset, Recmodel, epoch, w=None, multicore=0):\n",
    "    u_batch_size = world.config['test_u_batch_size']\n",
    "    dataset: utils.BasicDataset\n",
    "    testDict: dict = dataset.testDict\n",
    "    Recmodel: model.LightGCN\n",
    "    # eval mode with no dropout\n",
    "    Recmodel = Recmodel.eval()\n",
    "    max_K = max(world.topks)\n",
    "    if multicore == 1:\n",
    "        pool = multiprocessing.Pool(CORES)\n",
    "    results = {'precision': np.zeros(len(world.topks)),\n",
    "               'recall': np.zeros(len(world.topks)),\n",
    "               'ndcg': np.zeros(len(world.topks))}\n",
    "    with torch.no_grad():\n",
    "        users = list(testDict.keys())\n",
    "        try:\n",
    "            assert u_batch_size <= len(users) / 10\n",
    "        except AssertionError:\n",
    "            print(f\"test_u_batch_size is too big for this dataset, try a small one {len(users) // 10}\")\n",
    "        users_list = []\n",
    "        rating_list = []\n",
    "        groundTrue_list = []\n",
    "        # auc_record = []\n",
    "        # ratings = []\n",
    "        total_batch = len(users) // u_batch_size + 1\n",
    "        for batch_users in utils.minibatch(users, batch_size=u_batch_size):\n",
    "            allPos = dataset.getUserPosItems(batch_users)\n",
    "            groundTrue = [testDict[u] for u in batch_users]\n",
    "            batch_users_gpu = torch.Tensor(batch_users).long()\n",
    "            batch_users_gpu = batch_users_gpu.to(world.device)\n",
    "\n",
    "            rating = Recmodel.getUsersRating(batch_users_gpu)\n",
    "            #rating = rating.cpu()\n",
    "            exclude_index = []\n",
    "            exclude_items = []\n",
    "            for range_i, items in enumerate(allPos):\n",
    "                exclude_index.extend([range_i] * len(items))\n",
    "                exclude_items.extend(items)\n",
    "            rating[exclude_index, exclude_items] = -(1<<10)\n",
    "            _, rating_K = torch.topk(rating, k=max_K)\n",
    "            rating = rating.cpu().numpy()\n",
    "            # aucs = [ \n",
    "            #         utils.AUC(rating[i],\n",
    "            #                   dataset, \n",
    "            #                   test_data) for i, test_data in enumerate(groundTrue)\n",
    "            #     ]\n",
    "            # auc_record.extend(aucs)\n",
    "            del rating\n",
    "            users_list.append(batch_users)\n",
    "            rating_list.append(rating_K.cpu())\n",
    "            groundTrue_list.append(groundTrue)\n",
    "        assert total_batch == len(users_list)\n",
    "        X = zip(rating_list, groundTrue_list)\n",
    "        if multicore == 1:\n",
    "            pre_results = pool.map(test_one_batch, X)\n",
    "        else:\n",
    "            pre_results = []\n",
    "            for x in X:\n",
    "                pre_results.append(test_one_batch(x))\n",
    "        scale = float(u_batch_size/len(users))\n",
    "        for result in pre_results:\n",
    "            results['recall'] += result['recall']\n",
    "            results['precision'] += result['precision']\n",
    "            results['ndcg'] += result['ndcg']\n",
    "        results['recall'] /= float(len(users))\n",
    "        results['precision'] /= float(len(users))\n",
    "        results['ndcg'] /= float(len(users))\n",
    "        # results['auc'] = np.mean(auc_record)\n",
    "        if world.tensorboard:\n",
    "            w.add_scalars(f'Test/Recall@{world.topks}',\n",
    "                          {str(world.topks[i]): results['recall'][i] for i in range(len(world.topks))}, epoch)\n",
    "            w.add_scalars(f'Test/Precision@{world.topks}',\n",
    "                          {str(world.topks[i]): results['precision'][i] for i in range(len(world.topks))}, epoch)\n",
    "            w.add_scalars(f'Test/NDCG@{world.topks}',\n",
    "                          {str(world.topks[i]): results['ndcg'][i] for i in range(len(world.topks))}, epoch)\n",
    "        if multicore == 1:\n",
    "            pool.close()\n",
    "        print(results)\n",
    "        return results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
